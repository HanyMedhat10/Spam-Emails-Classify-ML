{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam_ham_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the overall aesthetic of the plots\n",
    "sns.set(style=\"whitegrid\")  # Professional style with grid\n",
    "\n",
    "# Use the 'Dark2' palette for professional color tones\n",
    "sns.histplot(data=df, x=\"label_num\", hue=\"label\", palette=\"Dark2\", edgecolor=\"black\", linewidth=1.5)\n",
    "\n",
    "plt.title(\"Distribution of Label Numbers\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Label Numbers\", fontsize=14)\n",
    "plt.ylabel(\"Counting\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['label_num'] == 0].index[1499:],  inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the overall aesthetic of the plots\n",
    "sns.set(style=\"whitegrid\")  # Professional style with grid\n",
    "\n",
    "# Use the 'Dark2' palette for professional color tones\n",
    "sns.histplot(data=df, x=\"label_num\", hue=\"label\", palette=\"Dark2\", edgecolor=\"black\", linewidth=1.5)\n",
    "\n",
    "plt.title(\"Distribution of Label Numbers\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Label Numbers\", fontsize=14)\n",
    "plt.ylabel(\"Counting\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Unnamed: 0\",'label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check through pie chart\n",
    "# labels = df['label_num'].value_counts().index\n",
    "labels = ['ham', 'spam']\n",
    "sizes = df['label_num'].value_counts().values\n",
    "colors = ['#FF9999', '#66B3FF', '#99FF99', '#FFCC99', '#FFD700']  # Define custom colors\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%')\n",
    "plt.axis('equal')  # Ensures the pie chart is a circle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to preprocess the text\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Remove the punctuations\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Tokenize the words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove stopwords and apply stemming (the library we use)\n",
    "    stop_words = stopwords.words('english')\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words = [stemmer.stem(word) for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X=tfidf_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "y=df[\"label_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_text, y_train, y_test=train_test_split(X, y ,test_size=0.2,random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"LogisticRegression\": lg,\n",
    "    \"KNN\": knn,\n",
    "    \"Decision Tree\": dtc,\n",
    "    \"Random Forest\": rfc,\n",
    "    \"XGBoost\": xgb,\n",
    "}\n",
    "\n",
    "best_results = {}\n",
    "best_model_name = None\n",
    "best_accuracy = 0.0 \n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Training  the model\n",
    "    y_pred = model.predict(X_text)  # Predict on the test set\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "    best_results[name] = accuracy  # Store accuracy in the results dictionary\n",
    "\n",
    "    # Display accuracy and classification report for the current model\n",
    "    print(f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Check if this is the best accuracy so far\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_name = name\n",
    "\n",
    "# Display the model with the best accuracy at the end\n",
    "print(\"\\nBest Model:\")\n",
    "print(f\"{best_model_name} with Accuracy: {best_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the models Accuracy \n",
    "\n",
    "# Define a color palette\n",
    "colors = ['#1f77b4', '#ff7f0e','#FF9999', '#66B3FF', '#99FF99', '#FFCC99', '#FFD700']  \n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(best_results.keys(), best_results.values(), color=colors)\n",
    "plt.title('Model Comparison', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Model', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.ylim(0.9, 1.0)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height + 0.01, f'{height:.2f}', \n",
    "             ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
